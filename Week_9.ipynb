{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cffe22a",
   "metadata": {},
   "source": [
    "# Create a neural network capable of identifying circles\n",
    "And make it run on a GPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6132fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "# import fuckit # could not get working in Anaconda - ket hitting other packages\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c69227fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 25 True 20 square\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "parameters = dict(\n",
    "    lr = [0.001],\n",
    "    batch_size = [25],\n",
    "    shuffle = [True],\n",
    "    epochs = [20],\n",
    "    train_shape = [\"square\"] # circle or square are supported\n",
    ")\n",
    "\n",
    "param_values = [value for value in parameters.values()]\n",
    "\n",
    "for lr, batch_size, shuffle, epochs, train_shape in product(*param_values): # Note: * here unpacks a three-tuple of three-tuples into just three three-tuples\n",
    "    print(lr, batch_size, shuffle, epochs, train_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2fca63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 100 # All our circles will be in square this many pixels wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e73300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_circleSlow(x,y,rad,size,mark=1):\n",
    "    \"\"\"\n",
    "    Create a binary 2D matrix representation of a circle\n",
    "    :param x: x coordinate of circle center\n",
    "    :param y: y coordinate of circle center\n",
    "    :param rad: radius of circle\n",
    "    :param size: size of the matrix (size x size)\n",
    "    :return: torch matrix (size x size) with 1s representing the circle\n",
    "    \"\"\"\n",
    "    pic = torch.zeros(size,size)\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            dx = i-x\n",
    "            dy = j-y\n",
    "            d2 = (dx*dx + dy*dy)\n",
    "            if abs(d2-(rad * rad)) < 10:\n",
    "                pic[i,j] = mark\n",
    "            else:\n",
    "                pic[i,j] = 0\n",
    "    return pic   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "068ade20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_write(pic,sz,x,y,mark):\n",
    "    if 0 <= x and x < sz and 0 <= y and y < sz:\n",
    "        pic[x, y] = mark\n",
    "\n",
    "# Bresenham circle\n",
    "# @fuckit\n",
    "def circ8(pic, xc, yc, x, y,mark=1, sz=100):\n",
    "    \"\"\"\n",
    "    Set 8 symmetric pixels for a circle\n",
    "    Note: fuckit decorator will silently ignore any excpetions below, most likely caused by a\n",
    "        poorly trained network attempting to guess a circle that is out of bounds\n",
    "    \"\"\"\n",
    "    clip_write(pic,sz,xc+x, yc+y,mark)\n",
    "    clip_write(pic,sz,xc-x, yc+y,mark)\n",
    "    clip_write(pic,sz,xc+x, yc-y,mark)\n",
    "    clip_write(pic,sz,xc-x, yc-y,mark)\n",
    "    clip_write(pic,sz,xc+y, yc+x,mark)\n",
    "    clip_write(pic,sz,xc-y, yc+x,mark)\n",
    "    clip_write(pic,sz,xc+y, yc-x,mark)\n",
    "    clip_write(pic,sz,xc-y, yc-x,mark)\n",
    "\n",
    "def draw_circleFast(xc,yc,radius,size, mark=1):    \n",
    "    \"\"\"\n",
    "    Draw circle using Bresenham algo\n",
    "    \"\"\"\n",
    "    \n",
    "    # make sure type is float32 pytorch tensor\n",
    "    pic = torch.zeros(size,size,dtype=torch.float32)\n",
    "    \n",
    "    x,y = 0,radius\n",
    "    err = 3 - 2 * radius\n",
    "    circ8(pic, xc, yc, x, y, mark)\n",
    "    while y >= x:    \n",
    "        x = x + 1\n",
    "        if err > 0:\n",
    "            y = y - 1\n",
    "            err = err + 4 * (x - y) + 10\n",
    "        else:\n",
    "            err = err + 4 * x + 6\n",
    "        circ8(pic, xc, yc, x, y, mark, size)\n",
    "    return pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dc1a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_square(xc, yc, side, size, mark=1):\n",
    "    \"\"\"\n",
    "    Draw square centered at xc,yc, sidelength side\n",
    "    \"\"\"\n",
    "    \n",
    "    # make sure type is float32 pytorch tensor\n",
    "    pic = torch.zeros(size,size,dtype=torch.float32)\n",
    "    \n",
    "    x1 = xc - side//2 # integer divide\n",
    "    x2 = x1 + side\n",
    "    \n",
    "    y1 = yc - side//2\n",
    "    y2 = y1 + side\n",
    "    \n",
    "    for i in range(x1,x2+1):\n",
    "        clip_write(pic,size,i,y1,mark)\n",
    "        clip_write(pic,size,i,y2,mark)\n",
    "    for j in range(y1,y2+1):\n",
    "        clip_write(pic,size,x1,j,mark)\n",
    "        clip_write(pic,size,x2,j,mark)\n",
    "    return pic    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32fe941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2D representation of a circle, radius 10 at (30,30)\n",
    "circ30 = draw_circleFast(30, 30, 10, IMG_SIZE)\n",
    "square30 = draw_square(30, 30, 10, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b0bd40f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circ30 # Output of draw_circle is a 2D array of mostly 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9af221c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1dc36123cd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot our square and circle\n",
    "plt.figure()\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.imshow(circ30) # Here's a visual representation of our circle\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.imshow(square30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a975099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels  = 1,\n",
    "                padding      = 0,\n",
    "                out_channels = 32, # may change?\n",
    "                kernel_size  =  5,  # may change\n",
    "                stride       =  3\n",
    "            ),\n",
    "            # image 100 wide, no padding, kernel 5, stride by 3\n",
    "            # first is [0,4], 2nd [3,7], 3rd [6,10], ... 32nd [93,97]\n",
    "            # this in each dim => 32x32 per channel from 100x100 input\n",
    "            #\n",
    "            # 32x32 - each channel recognizes a feature\n",
    "            #\n",
    "            # 32 channels => 32^3\n",
    "            #\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(\n",
    "                in_channels  = 32,\n",
    "                padding      = 0,\n",
    "                out_channels = 5, # may change?\n",
    "                kernel_size  = 9  # may change\n",
    "            ),\n",
    "            nn.Flatten(),\n",
    "            # 5 is out channels, 32 is in size to last conv2d, -8 for kernel size 9\n",
    "            nn.Linear(5 * (32 - 8) * (32 - 8), 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 512),\n",
    "            #nn.Linear(512, 400000), # idiots were here\n",
    "            #nn.Linear(400000, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, our_data):\n",
    "        x = self.net(our_data)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5024256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (net): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(3, 3))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Conv2d(32, 5, kernel_size=(9, 9), stride=(1, 1))\n",
       "    (3): Flatten(start_dim=1, end_dim=-1)\n",
       "    (4): Linear(in_features=2880, out_features=2048, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=512, out_features=3, bias=True)\n",
       "    (9): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_net = NeuralNetwork() # Create an instance of our neural network class, name it \"net\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Get the cuda device\n",
    "print(device)\n",
    "test_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "166234dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_used():\n",
    "    \"\"\"GB used by CUDA\"\"\"\n",
    "    print(\"{:.2f} GiB\".format(torch.cuda.memory_allocated() / (1024*1024*1024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c54268ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03 GiB\n"
     ]
    }
   ],
   "source": [
    "mem_used()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "597177e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Massage circ30 (a 2D array of mostly 0s and some 1s representing a circle) into something we can use\n",
    "net_input = circ30.unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1340f114",
   "metadata": {},
   "source": [
    "Note: According to https://stackoverflow.com/a/59566009 Conv2D and many other layers expect input conforming to (n_samples, channels, height, width) # e.g., (1000, 1, 224, 224)\n",
    "\n",
    "So the two unsqueezes above simply pad the input with 1 sample dimension and 1 channel dimension [100, 100] -> [1, 1, 100, 100]\n",
    "\n",
    "Also, unsqueeze seems like it's helpful for hacking stuff together early on - it just adds a dimension at the specified index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c70462e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 100, 100])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_input.shape # Our network input is of shape [1, 1, 100, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eed872a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = test_net(net_input.to(device)) # Run input through the network - No training being done here, just one forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77c89590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.shape # Show the shape of our network output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d79d22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1362, 0.0000]], device='cuda:0', grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3a73a6",
   "metadata": {},
   "source": [
    "# Create Training Data for Classifying Circles\n",
    "### We already have a circle function draw_circle(), so we just need to utilize it to create a bunch of circles matched with their radius and origin\n",
    "Following https://pytorch.org/tutorials/beginner/data_loading_tutorial.html for the below steps on how to add custom data and datasets and manipulate them via a Dataloader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8d7f61",
   "metadata": {},
   "source": [
    "### Create a custom dataset to hold our training data\n",
    "##### Dataset class\n",
    "torch.utils.data.Dataset is an abstract class representing a dataset. Your custom dataset should inherit Dataset and override the following methods  \n",
    "* \\_\\_len__ so that len(dataset) returns the size of the dataset.  \n",
    "* \\_\\_getitem__ to support the indexing such that dataset[i] can be used to get iith sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb1083eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeDataset(Dataset):\n",
    "    def __init__(self, shapeFunc, num_shapes=10000, param_min=5,param_max=20, size=100):\n",
    "        randomlist=[] # List of shapes generated somewhat randomly based on position and radius\n",
    "        truthlist=[] # Cooresponding position and a parameter  for the generated shapes\n",
    "        for i in range(num_shapes):\n",
    "            parameter = random.randint(param_min, param_max)\n",
    "            x = random.randint(parameter,size-parameter-1)\n",
    "            y = random.randint(parameter,size-parameter-1)\n",
    "            s = shapeFunc(x,y,parameter,size).unsqueeze(0)\n",
    "            # Recall tensors fed through our network must have a \"channels\" dimension, in this case it's one, so we will use unsqueeze again to add it\n",
    "            # If we had e.g. Red, Green, and Blue data, we would split that into three 100x100 channels\n",
    "            # \"single\" is chosen here because it seems to be the only numpy type that plays nice with torch.double that are used throughout the network\n",
    "            truthlist.append(np.array([x,y,parameter], dtype=np.single))\n",
    "            randomlist.append(s)\n",
    "        self.samples = randomlist # Shapes\n",
    "        self.truth = truthlist # Attributes of those shapes\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self,idx):\n",
    "        sample = {'shape': self.samples[idx], 'attributes': self.truth[idx]}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caf1268",
   "metadata": {},
   "source": [
    "### Using a dataloader allows us to\n",
    "* Batch the data\n",
    "* Shuffle the data\n",
    "* Load the data in parallel using multiprocessing workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d22b2a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_network(network, verbose=False, draw_func=draw_circleFast):\n",
    "    radius = random.randint(4, 20)\n",
    "    x = random.randint(radius,100-radius)\n",
    "    y = random.randint(radius,100-radius)\n",
    "    shape = draw_func(x,y,radius,100).unsqueeze(0).unsqueeze(0)\n",
    "    ans = network(shape.to(device))\n",
    "    if verbose:\n",
    "        print(\"For shape at ({}, {}), r={}, net guessed:\\n{}\".format(str(x), str(y), str(radius), str(ans)))\n",
    "    truth = draw_func(x, y, radius, IMG_SIZE, 0.2)\n",
    "    guess = draw_func(int(ans[0][0]), int(ans[0][1]), int(ans[0][2]), IMG_SIZE)\n",
    "    return (truth + guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a82977b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_network_splatter(network, num_checks=10, writer=None, verbose=False, draw_func=draw_circleFast):\n",
    "    \"\"\"\n",
    "    Given a network and a draw function, call check_network() for the network some number of times\n",
    "    and plot the results of the check function in a single figure\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    num_cols = 5\n",
    "    num_rows = int((num_checks / num_cols) + (1 if (num_checks % num_cols) == 0 else 0))\n",
    "    fig = plt.figure(figsize=(20,10))#f, canvas = plt.subplots(num_rows, num_cols)\n",
    "    for check in range(num_checks):\n",
    "        fig.add_subplot(num_rows, num_cols, check + 1) # + 1 because range is 0-indexed but pyplot is 1-indexed\n",
    "        plt.imshow(check_network(network, verbose=verbose, draw_func=draw_func))\n",
    "    # Add this figure to the tensorboard log\n",
    "    if writer is not None:\n",
    "        writer.add_figure(\"Network Splatter\", fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c16034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(learning_rate, batch_size, shuffle=True, epochs=40):\n",
    "    import time\n",
    "    \n",
    "    net = NeuralNetwork().to(device)\n",
    "    trainloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=0)\n",
    "        \n",
    "    # SummaryWriter will store metrics to use with TensorBoard\n",
    "    comment = f' batch_size={batch_size} lr={lr} shuffle={shuffle} epochs={epochs}'\n",
    "    writer = SummaryWriter(comment=comment)\n",
    "            \n",
    "    #loss_func = nn.functional.cross_entropy # Cross entropy only works for 1D tensors\n",
    "    #loss_func = nn.L1Loss()\n",
    "    loss_func = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # initialize empty list to track batch losses\n",
    "    batch_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Reset Iterator\n",
    "        dataiter = iter(trainloader)\n",
    "        \n",
    "        # Keep track of batch number\n",
    "        batch_number = 0\n",
    "        \n",
    "        # Keep track of time \n",
    "        last_time = time.time()\n",
    "        last_epoch = time.time()\n",
    "        \n",
    "        # Keep track of per-epoch stats\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in dataiter:\n",
    "            batch_number += 1\n",
    "            \n",
    "            # Reset Gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward Pass through the network\n",
    "            out = net(batch[\"shape\"].to(device))\n",
    "        \n",
    "            # Calculate loss\n",
    "            loss = loss_func(out, batch[\"attributes\"].to(device)) # Compare our results with the truth data\n",
    "            \n",
    "            # Log the loss for TensorBoard analysis\n",
    "            # NOTE: we can track loss per batch, as this statement does, or do it per epoch later\n",
    "            #writer.add_scalar(\"Loss/train\", loss, epoch * len(dataloader) + batch_number)\n",
    "            \n",
    "            # track batch loss\n",
    "            batch_losses.append(loss.item()) # TODO what does batch_losses do?\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Backpropagate\n",
    "            loss.backward()\n",
    "                \n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Time things\n",
    "            next_time = time.time()\n",
    "            delta_time = next_time - last_time\n",
    "            last_time = next_time\n",
    "            \n",
    "        # print any stats of the network wrt training progress and loss\n",
    "        # Time things\n",
    "        next_epoch = time.time()\n",
    "        delta_epoch = next_epoch - last_epoch\n",
    "        last_epoch = next_epoch\n",
    "        # if ((epoch % 10 == 0) or (epoch % 39 == 0)) and False:\n",
    "        print(\"run_id: {}, Epoch: {}, DeltaTime = {:.2f}, LastLoss = {:.2f}\".format(\n",
    "            str(run_id),\n",
    "            str(epoch), # Epoch\n",
    "            delta_epoch,\n",
    "            epoch_loss)) # What is the loss for this batch\n",
    "        \n",
    "        # Note, \"net\" here is our neural network instance.  It looks like this:\n",
    "        \"\"\"NeuralNetwork(\n",
    "          (net): Sequential(\n",
    "            (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(3, 3))\n",
    "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): Conv2d(32, 5, kernel_size=(9, 9), stride=(1, 1))\n",
    "            (3): Flatten(start_dim=1, end_dim=-1)\n",
    "            (4): Linear(in_features=2880, out_features=2048, bias=True)\n",
    "            (5): ReLU()\n",
    "            (6): Linear(in_features=2048, out_features=512, bias=True)\n",
    "            (7): ReLU()\n",
    "            (8): Linear(in_features=512, out_features=3, bias=True)\n",
    "            (9): ReLU()\n",
    "          )\n",
    "        )\n",
    "        \"\"\"\n",
    "        # epoch stats\n",
    "        writer.add_scalar(\"Loss/train\", epoch_loss, epoch)\n",
    "        writer.add_histogram(\"conv1.bias\",   net.net[0].bias, epoch)\n",
    "        writer.add_histogram(\"conv1.weight\", net.net[0].weight, epoch)\n",
    "        writer.add_histogram(\"conv2.bias\",   net.net[0].bias, epoch)\n",
    "        writer.add_histogram(\"conv2.weight\", net.net[0].weight, epoch)\n",
    "               \n",
    "    # See how the network did.\n",
    "    check_network_splatter(net, writer=writer)\n",
    "    writer.close()\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc526cd7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset for shape square with 100000 samples\n",
      "Training network with LR=0.001 BATCH=25, SHUFFLE=True, EPOCHS=20\n",
      "run_id: 0, Epoch: 0, DeltaTime = 12.03, LastLoss = 54011.75\n",
      "run_id: 0, Epoch: 1, DeltaTime = 11.87, LastLoss = 14473.63\n",
      "run_id: 0, Epoch: 2, DeltaTime = 11.88, LastLoss = 8476.64\n",
      "run_id: 0, Epoch: 3, DeltaTime = 11.93, LastLoss = 5170.42\n",
      "run_id: 0, Epoch: 4, DeltaTime = 11.97, LastLoss = 3659.85\n",
      "run_id: 0, Epoch: 5, DeltaTime = 11.91, LastLoss = 2669.47\n",
      "run_id: 0, Epoch: 6, DeltaTime = 11.89, LastLoss = 2176.33\n",
      "run_id: 0, Epoch: 7, DeltaTime = 11.87, LastLoss = 1804.12\n",
      "run_id: 0, Epoch: 8, DeltaTime = 11.89, LastLoss = 1538.59\n",
      "run_id: 0, Epoch: 9, DeltaTime = 11.88, LastLoss = 1379.90\n",
      "run_id: 0, Epoch: 10, DeltaTime = 11.97, LastLoss = 1293.80\n",
      "run_id: 0, Epoch: 11, DeltaTime = 12.09, LastLoss = 1224.45\n",
      "run_id: 0, Epoch: 12, DeltaTime = 11.88, LastLoss = 1167.10\n",
      "run_id: 0, Epoch: 13, DeltaTime = 11.91, LastLoss = 1055.21\n",
      "run_id: 0, Epoch: 14, DeltaTime = 11.91, LastLoss = 1054.35\n",
      "run_id: 0, Epoch: 15, DeltaTime = 11.90, LastLoss = 902.50\n",
      "run_id: 0, Epoch: 16, DeltaTime = 11.92, LastLoss = 908.43\n",
      "run_id: 0, Epoch: 17, DeltaTime = 11.93, LastLoss = 900.49\n",
      "run_id: 0, Epoch: 18, DeltaTime = 11.93, LastLoss = 855.30\n",
      "run_id: 0, Epoch: 19, DeltaTime = 11.93, LastLoss = 823.97\n",
      "For shape at (18, 14), r=9, net guessed:\n",
      "tensor([[18.2587, 13.6509,  9.5827]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "For shape at (78, 45), r=16, net guessed:\n",
      "tensor([[76.5994, 44.6095, 15.6103]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "For shape at (72, 70), r=9, net guessed:\n",
      "tensor([[72.1031, 71.1720,  8.8726]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "For shape at (66, 56), r=19, net guessed:\n",
      "tensor([[65.8091, 55.5339, 18.2122]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "For shape at (63, 68), r=20, net guessed:\n",
      "tensor([[62.8561, 68.5788, 19.0698]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "For shape at (86, 52), r=11, net guessed:\n",
      "tensor([[85.3709, 52.5880, 10.8485]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "For shape at (25, 73), r=7, net guessed:\n",
      "tensor([[24.6831, 71.0066,  7.3511]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "For shape at (81, 22), r=11, net guessed:\n",
      "tensor([[79.6891, 22.2430, 10.0235]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "For shape at (31, 57), r=18, net guessed:\n",
      "tensor([[30.5870, 56.9069, 17.5728]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "For shape at (38, 65), r=8, net guessed:\n",
      "tensor([[37.4710, 63.7467,  7.2421]], device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for run_id, (lr, batch_size, shuffle, epochs, train_shape) in enumerate(product(*param_values)):\n",
    "    dataset_size = 100000 # Should this be a hyperparameter?\n",
    "    print(\"Creating dataset for shape {} with {} samples\".format(train_shape, dataset_size))\n",
    "    draw_func = draw_square if (train_shape == \"square\") else draw_circleFast\n",
    "    dataset = ShapeDataset(draw_square, dataset_size)\n",
    "    \n",
    "    print(\"Training network with LR={} BATCH={}, SHUFFLE={}, EPOCHS={}\".format(lr, batch_size, str(shuffle), epochs))\n",
    "    netout = train(lr, batch_size, shuffle, epochs)\n",
    "    check_network_splatter(netout, draw_func=draw_func, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecd85630",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08 GiB\n"
     ]
    }
   ],
   "source": [
    "mem_used()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "723e8133",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   81959 KB |  182458 KB |    8402 GB |    8402 GB |\n",
      "|       from large pool |   81408 KB |  181760 KB |    8191 GB |    8191 GB |\n",
      "|       from small pool |     551 KB |    2610 KB |     210 GB |     210 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   81959 KB |  182458 KB |    8402 GB |    8402 GB |\n",
      "|       from large pool |   81408 KB |  181760 KB |    8191 GB |    8191 GB |\n",
      "|       from small pool |     551 KB |    2610 KB |     210 GB |     210 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  217088 KB |  217088 KB |  217088 KB |       0 B  |\n",
      "|       from large pool |  212992 KB |  212992 KB |  212992 KB |       0 B  |\n",
      "|       from small pool |    4096 KB |    4096 KB |    4096 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   14297 KB |   36731 KB |    4171 GB |    4171 GB |\n",
      "|       from large pool |   12800 KB |   34593 KB |    3840 GB |    3840 GB |\n",
      "|       from small pool |    1497 KB |    2148 KB |     330 GB |     330 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |      54    |      95    |    5120 K  |    5120 K  |\n",
      "|       from large pool |       6    |      14    |     960 K  |     960 K  |\n",
      "|       from small pool |      48    |      83    |    4160 K  |    4160 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |      54    |      95    |    5120 K  |    5120 K  |\n",
      "|       from large pool |       6    |      14    |     960 K  |     960 K  |\n",
      "|       from small pool |      48    |      83    |    4160 K  |    4160 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      11    |      11    |      11    |       0    |\n",
      "|       from large pool |       9    |       9    |       9    |       0    |\n",
      "|       from small pool |       2    |       2    |       2    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       9    |      16    |    2840 K  |    2840 K  |\n",
      "|       from large pool |       5    |      10    |     560 K  |     560 K  |\n",
      "|       from small pool |       4    |       8    |    2280 K  |    2280 K  |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d824ce7",
   "metadata": {},
   "source": [
    "Run this command from the dirctory containing \"logdir\" to stand up tensorboard log viewer\n",
    "```sh\n",
    "tensorboard --logdir=runs\n",
    "```\n",
    "Then go to http://localhost:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d565ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e660af3098993ea5160fd9270f74e6db286e749e474b6bbf115c5a1892218496"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
