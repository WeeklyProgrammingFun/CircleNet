{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "revised-clothing",
   "metadata": {},
   "source": [
    "# Today's challenge: Create a neural network capable of identifying circles\n",
    "Bonus points for identifying circle center and radius?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sharp-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cultural-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 100 # All our circles will be in square this many pixels wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "overall-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_circle(x,y,rad,size):\n",
    "    \"\"\"\n",
    "    Create a binary 2D matrix representation of a circle\n",
    "    :param x: x coordinate of circle center\n",
    "    :param y: y coordinate of circle center\n",
    "    :param rad: radius of circle\n",
    "    :param size: size of the matrix (size x size)\n",
    "    :return: torch matrix (size x size) with 1s representing the circle\n",
    "    \"\"\"\n",
    "    pic = torch.zeros(size,size)\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            dx = i-x\n",
    "            dy = j-y\n",
    "            d = math.sqrt(dx*dx + dy*dy)\n",
    "            if abs(d-rad) < 1.5:\n",
    "                pic[i,j] = 1\n",
    "            else:\n",
    "                pic[i,j] = 0\n",
    "    return pic   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "static-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2D representation of a circle, radius 10 at (30,30)\n",
    "circ30 = draw_circle(30, 30, 10, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "incident-helen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circ30 # Output of draw_circle is a 2D array of mostly 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "planned-honduras",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f87f2079e8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(circ30) # Here's a visual representation of our circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ambient-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "    class NeuralNetwork(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(NeuralNetwork, self).__init__()\n",
    "\n",
    "            self.conv_stage_1 = nn.Conv2d(\n",
    "                in_channels  = 1,\n",
    "                padding      = 0,\n",
    "                out_channels = 1, # may change?\n",
    "                kernel_size  = 4  # may change\n",
    "                )\n",
    "\n",
    "            self.flatten = nn.Flatten()\n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(28*28, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 10),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "        def forward(self, our_data):\n",
    "            x2 = self.conv_stage_1(our_data)\n",
    "            # x2 = self.flatten(x1)\n",
    "            # logits = self.linear_relu_stack(x2)\n",
    "            # return logits\n",
    "            return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abandoned-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetwork() # Create an instance of our neural network class, name it \"net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unlikely-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Massage circ30 (a 2D array of mostly 0s and some 1s representing a circle) into something we can use\n",
    "net_input = circ30.unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-cancellation",
   "metadata": {},
   "source": [
    "Note: According to https://stackoverflow.com/a/59566009 Conv2D and many other layers expect input conforming to (n_samples, channels, height, width) # e.g., (1000, 1, 224, 224)\n",
    "\n",
    "So the two unsqueezes above simply pad the input with 1 sample dimension and 1 channel dimension [100, 100] -> [1, 1, 100, 100]\n",
    "\n",
    "Also, unsqueeze seems like it's helpful for hacking stuff together early on - it just adds a dimension at the specified index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "equivalent-method",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 100, 100])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_input.shape # Our network input is of shape [1, 1, 100, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "material-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = net(net_input) # Run input through the network - No training being done here, just one forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "chemical-above",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 97, 97])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.shape # Show the shape of our network output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-charger",
   "metadata": {},
   "source": [
    "### Question: We lose 3 pixels (100 -> 97).  Why?  Padding?  Stride?  Kernel Size?\n",
    "\n",
    "If the kernal is focused near the edge of the picture, we could lose some data (unless we pad the edges by the correct amount) Given padding of 0 and kernel size 4, we likely lose one pixel to the edge on one side and two pixels to the edge on the other side.\n",
    "\n",
    "I think the best way to make sure the image doesn't shrink or embiggen is to use an odd sized kernel (so we use same padding/overlap on all sides) and have a padding of (kernel size / 2) rounded down to account for the remainder pixel in the middle.\n",
    "\n",
    "Alternatively, If the stride is such that we \"skip\" some pixels, the image will be shrunk (not the case here though stride = 1 so we hit every pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "soviet-article",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1684, -0.1684, -0.1684,  ..., -0.1684, -0.1684, -0.1684],\n",
       "          [-0.1684, -0.1684, -0.1684,  ..., -0.1684, -0.1684, -0.1684],\n",
       "          [-0.1684, -0.1684, -0.1684,  ..., -0.1684, -0.1684, -0.1684],\n",
       "          ...,\n",
       "          [-0.1684, -0.1684, -0.1684,  ..., -0.1684, -0.1684, -0.1684],\n",
       "          [-0.1684, -0.1684, -0.1684,  ..., -0.1684, -0.1684, -0.1684],\n",
       "          [-0.1684, -0.1684, -0.1684,  ..., -0.1684, -0.1684, -0.1684]]]],\n",
       "       grad_fn=<MkldnnConvolutionBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
