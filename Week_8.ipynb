{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cffe22a",
   "metadata": {},
   "source": [
    "# Create a neural network capable of identifying circles\n",
    "And make it run on a GPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6132fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "# import fuckit # could not get working in Anaconda - ket hitting other packages\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c69227fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 25 True 20\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "parameters = dict(\n",
    "    lr = [0.001],\n",
    "    batch_size = [25],\n",
    "    shuffle = [True],\n",
    "    epochs = [20]\n",
    ")\n",
    "\n",
    "param_values = [value for value in parameters.values()]\n",
    "\n",
    "for lr, batch_size, shuffle, epochs in product(*param_values): # Note: * here unpacks a three-tuple of three-tuples into just three three-tuples\n",
    "    print(lr, batch_size, shuffle, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2fca63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 100 # All our circles will be in square this many pixels wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e73300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_circleSlow(x,y,rad,size,mark=1):\n",
    "    \"\"\"\n",
    "    Create a binary 2D matrix representation of a circle\n",
    "    :param x: x coordinate of circle center\n",
    "    :param y: y coordinate of circle center\n",
    "    :param rad: radius of circle\n",
    "    :param size: size of the matrix (size x size)\n",
    "    :return: torch matrix (size x size) with 1s representing the circle\n",
    "    \"\"\"\n",
    "    pic = torch.zeros(size,size)\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            dx = i-x\n",
    "            dy = j-y\n",
    "            d2 = (dx*dx + dy*dy)\n",
    "            if abs(d2-(rad * rad)) < 10:\n",
    "                pic[i,j] = mark\n",
    "            else:\n",
    "                pic[i,j] = 0\n",
    "    return pic   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "068ade20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_write(pic,sz,x,y,mark):\n",
    "    if 0 <= x and x < sz and 0 <= y and y < sz:\n",
    "        pic[x, y] = mark\n",
    "\n",
    "# Bresenham circle\n",
    "# @fuckit\n",
    "def circ8(pic, xc, yc, x, y,mark=1, sz=100):\n",
    "    \"\"\"\n",
    "    Set 8 symmetric pixels for a circle\n",
    "    Note: fuckit decorator will silently ignore any excpetions below, most likely caused by a\n",
    "        poorly trained network attempting to guess a circle that is out of bounds\n",
    "    \"\"\"\n",
    "    clip_write(pic,sz,xc+x, yc+y,mark)\n",
    "    clip_write(pic,sz,xc-x, yc+y,mark)\n",
    "    clip_write(pic,sz,xc+x, yc-y,mark)\n",
    "    clip_write(pic,sz,xc-x, yc-y,mark)\n",
    "    clip_write(pic,sz,xc+y, yc+x,mark)\n",
    "    clip_write(pic,sz,xc-y, yc+x,mark)\n",
    "    clip_write(pic,sz,xc+y, yc-x,mark)\n",
    "    clip_write(pic,sz,xc-y, yc-x,mark)\n",
    "\n",
    "def draw_circleFast(xc,yc,radius,size, mark=1):    \n",
    "    \"\"\"\n",
    "    Draw circle using Bresenham algo\n",
    "    \"\"\"\n",
    "    \n",
    "    # make sure type is float32 pytorch tensor\n",
    "    pic = torch.zeros(size,size,dtype=torch.float32)\n",
    "    \n",
    "    x,y = 0,radius\n",
    "    err = 3 - 2 * radius\n",
    "    circ8(pic, xc, yc, x, y, mark)\n",
    "    while y >= x:    \n",
    "        x = x + 1\n",
    "        if err > 0:\n",
    "            y = y - 1\n",
    "            err = err + 4 * (x - y) + 10\n",
    "        else:\n",
    "            err = err + 4 * x + 6\n",
    "        circ8(pic, xc, yc, x, y, mark, size)\n",
    "    return pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dc1a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_square(xc,yc,side,size,mark=1):\n",
    "    \"\"\"\n",
    "    Draw square centered at xc,yc, sidelength side\n",
    "    \"\"\"\n",
    "    \n",
    "    # make sure type is float32 pytorch tensor\n",
    "    pic = torch.zeros(size,size,dtype=torch.float32)\n",
    "    \n",
    "    x1 = xc - side//2 # integer divide\n",
    "    x2 = x1 + side\n",
    "    \n",
    "    y1 = yc - side//2\n",
    "    y2 = y1 + side\n",
    "    \n",
    "    for i in range(x1,x2+1):\n",
    "        clip_write(pic,size,i,y1,mark)\n",
    "        clip_write(pic,size,i,y2,mark)\n",
    "    for j in range(y1,y2+1):\n",
    "        clip_write(pic,size,x1,j,mark)\n",
    "        clip_write(pic,size,x2,j,mark)\n",
    "    return pic    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32fe941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2D representation of a circle, radius 10 at (30,30)\n",
    "circ30 = draw_circleFast(30, 30, 10, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b0bd40f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circ30 # Output of draw_circle is a 2D array of mostly 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b4f1626",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq30 = draw_square(30,30,10,IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9af221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chris crashes for now....\n",
    "# plt.imshow(circ30) # Here's a visual representation of our circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a975099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels  = 1,\n",
    "                padding      = 0,\n",
    "                out_channels = 32, # may change?\n",
    "                kernel_size  =  5,  # may change\n",
    "                stride       =  3\n",
    "            ),\n",
    "            # image 100 wide, no padding, kernel 5, stride by 3\n",
    "            # first is [0,4], 2nd [3,7], 3rd [6,10], ... 32nd [93,97]\n",
    "            # this in each dim => 32x32 per channel from 100x100 input\n",
    "            #\n",
    "            # 32x32 - each channel recognizes a feature\n",
    "            #\n",
    "            # 32 channels => 32^3\n",
    "            #\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(\n",
    "                in_channels  = 32,\n",
    "                padding      = 0,\n",
    "                out_channels = 5, # may change?\n",
    "                kernel_size  = 9  # may change\n",
    "            ),\n",
    "            nn.Flatten(),\n",
    "            # 5 is out channels, 32 is in size to last conv2d, -8 for kernel size 9\n",
    "            nn.Linear(5 * (32 - 8) * (32 - 8), 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 512),\n",
    "            #nn.Linear(512, 400000), # idiots were here\n",
    "            #nn.Linear(400000, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, our_data):\n",
    "        x = self.net(our_data)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5024256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (net): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(3, 3))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Conv2d(32, 5, kernel_size=(9, 9), stride=(1, 1))\n",
       "    (3): Flatten(start_dim=1, end_dim=-1)\n",
       "    (4): Linear(in_features=2880, out_features=2048, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=512, out_features=3, bias=True)\n",
       "    (9): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_net = NeuralNetwork() # Create an instance of our neural network class, name it \"net\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Get the cuda device\n",
    "print(device)\n",
    "test_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "166234dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_used():\n",
    "    \"\"\"GB used by CUDA\"\"\"\n",
    "    print(\"{:.2f} GiB\".format(torch.cuda.memory_allocated() / (1024*1024*1024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c54268ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03 GiB\n"
     ]
    }
   ],
   "source": [
    "mem_used()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "597177e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Massage circ30 (a 2D array of mostly 0s and some 1s representing a circle) into something we can use\n",
    "net_input = circ30.unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1340f114",
   "metadata": {},
   "source": [
    "Note: According to https://stackoverflow.com/a/59566009 Conv2D and many other layers expect input conforming to (n_samples, channels, height, width) # e.g., (1000, 1, 224, 224)\n",
    "\n",
    "So the two unsqueezes above simply pad the input with 1 sample dimension and 1 channel dimension [100, 100] -> [1, 1, 100, 100]\n",
    "\n",
    "Also, unsqueeze seems like it's helpful for hacking stuff together early on - it just adds a dimension at the specified index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c70462e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 100, 100])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_input.shape # Our network input is of shape [1, 1, 100, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eed872a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = test_net(net_input.to(device)) # Run input through the network - No training being done here, just one forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77c89590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.shape # Show the shape of our network output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d79d22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0696, 0.0254]], device='cuda:0', grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3a73a6",
   "metadata": {},
   "source": [
    "# Create Training Data for Classifying Circles\n",
    "### We already have a circle function draw_circle(), so we just need to utilize it to create a bunch of circles matched with their radius and origin\n",
    "Following https://pytorch.org/tutorials/beginner/data_loading_tutorial.html for the below steps on how to add custom data and datasets and manipulate them via a Dataloader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8d7f61",
   "metadata": {},
   "source": [
    "### Create a custom dataset to hold our training data\n",
    "##### Dataset class\n",
    "torch.utils.data.Dataset is an abstract class representing a dataset. Your custom dataset should inherit Dataset and override the following methods  \n",
    "* \\_\\_len__ so that len(dataset) returns the size of the dataset.  \n",
    "* \\_\\_getitem__ to support the indexing such that dataset[i] can be used to get iith sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb1083eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeDataset(Dataset):\n",
    "    def __init__(self, shapeFunc, num_shapes=10000, param_min=5,param_max=20, size=100):\n",
    "        randomlist=[] # List of shapes generated somewhat randomly based on position and radius\n",
    "        truthlist=[] # Cooresponding position and a parameter  for the generated shapes\n",
    "        for i in range(num_shapes):\n",
    "            parameter = random.randint(param_min, param_max)\n",
    "            x = random.randint(parameter,size-parameter-1)\n",
    "            y = random.randint(parameter,size-parameter-1)\n",
    "            s = shapeFunc(x,y,parameter,size).unsqueeze(0)\n",
    "            # Recall tensors fed through our network must have a \"channels\" dimension, in this case it's one, so we will use unsqueeze again to add it\n",
    "            # If we had e.g. Red, Green, and Blue data, we would split that into three 100x100 channels\n",
    "            # \"single\" is chosen here because it seems to be the only numpy type that plays nice with torch.double that are used throughout the network\n",
    "            truthlist.append(np.array([x,y,parameter], dtype=np.single))\n",
    "            randomlist.append(s)\n",
    "        self.samples = randomlist # Shapes\n",
    "        self.truth = truthlist # Attributes of those shapes\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self,idx):\n",
    "        sample = {'shape': self.samples[idx], 'attributes': self.truth[idx]}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3ea45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = ShapeDataset(draw_circleFast, 100000)\n",
    "dataset = ShapeDataset(draw_square, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caf1268",
   "metadata": {},
   "source": [
    "### Using a dataloader allows us to\n",
    "* Batch the data\n",
    "* Shuffle the data\n",
    "* Load the data in parallel using multiprocessing workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d22b2a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_circle_network(network, verbose=False):\n",
    "    radius = random.randint(4, 20)\n",
    "    x = random.randint(radius,100-radius)\n",
    "    y = random.randint(radius,100-radius)\n",
    "    circle = draw_circleFast(x,y,radius,100).unsqueeze(0).unsqueeze(0)\n",
    "    ans = network(circle.to(device))\n",
    "    if verbose:\n",
    "        print(\"For circle at ({}, {}), r={}, net guessed:\\n{}\".format(str(x), str(y), str(radius), str(ans)))\n",
    "    truth = draw_circleFast(x, y, radius, IMG_SIZE, 0.2)\n",
    "    guess = draw_circleFast(int(ans[0][0]), int(ans[0][1]), int(ans[0][2]), IMG_SIZE)\n",
    "    return (truth + guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a82977b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_network_splatter(network, num_checks=10, writer=None, verbose=False):\n",
    "    plt.figure()\n",
    "    num_cols = 5\n",
    "    num_rows = int((num_checks / num_cols) + (1 if (num_checks % num_cols) == 0 else 0))\n",
    "    fig = plt.figure(figsize=(20,10))#f, canvas = plt.subplots(num_rows, num_cols)\n",
    "    for check in range(num_checks):\n",
    "        fig.add_subplot(num_rows, num_cols, check + 1) # + 1 because range is 0-indexed but pyplot is 1-indexed\n",
    "        plt.imshow(check_circle_network(network))\n",
    "    # Add this figure to the tensorboard log\n",
    "    if writer is not None:\n",
    "        writer.add_figure(\"Network Splatter\", fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c16034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(learning_rate, batch_size, shuffle=True, epochs=40):\n",
    "    import time\n",
    "    \n",
    "    net = NeuralNetwork().to(device)\n",
    "    trainloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=0)\n",
    "        \n",
    "    # SummaryWriter will store metrics to use with TensorBoard\n",
    "    comment = f' batch_size={batch_size} lr={lr} shuffle={shuffle} epochs={epochs}'\n",
    "    writer = SummaryWriter(comment=comment)\n",
    "            \n",
    "    #loss_func = nn.functional.cross_entropy # Cross entropy only works for 1D tensors\n",
    "    #loss_func = nn.L1Loss()\n",
    "    loss_func = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # initialize empty list to track batch losses\n",
    "    batch_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Reset Iterator\n",
    "        dataiter = iter(trainloader)\n",
    "        \n",
    "        # Keep track of batch number\n",
    "        batch_number = 0\n",
    "        \n",
    "        # Keep track of time \n",
    "        last_time = time.time()\n",
    "        last_epoch = time.time()\n",
    "        \n",
    "        # Keep track of per-epoch stats\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in dataiter:\n",
    "            batch_number += 1\n",
    "            \n",
    "            # Reset Gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward Pass through the network\n",
    "            out = net(batch[\"shape\"].to(device))\n",
    "        \n",
    "            # Calculate loss\n",
    "            loss = loss_func(out, batch[\"attributes\"].to(device)) # Compare our results with the truth data\n",
    "            \n",
    "            # Log the loss for TensorBoard analysis\n",
    "            # NOTE: we can track loss per batch, as this statement does, or do it per epoch later\n",
    "            #writer.add_scalar(\"Loss/train\", loss, epoch * len(dataloader) + batch_number)\n",
    "            \n",
    "            # track batch loss\n",
    "            batch_losses.append(loss.item()) # TODO what does batch_losses do?\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Backpropagate\n",
    "            loss.backward()\n",
    "                \n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Time things\n",
    "            next_time = time.time()\n",
    "            delta_time = next_time - last_time\n",
    "            last_time = next_time\n",
    "            \n",
    "        # print any stats of the network wrt training progress and loss\n",
    "        # Time things\n",
    "        next_epoch = time.time()\n",
    "        delta_epoch = next_epoch - last_epoch\n",
    "        last_epoch = next_epoch\n",
    "        # if ((epoch % 10 == 0) or (epoch % 39 == 0)) and False:\n",
    "        print(\"run_id: {}, Epoch: {}, DeltaTime = {:.2f}, LastLoss = {:.2f}\".format(\n",
    "            str(run_id),\n",
    "            str(epoch), # Epoch\n",
    "            delta_epoch,\n",
    "            epoch_loss)) # What is the loss for this batch\n",
    "        \n",
    "        # Note, \"net\" here is our neural network instance.  It looks like this:\n",
    "        \"\"\"NeuralNetwork(\n",
    "          (net): Sequential(\n",
    "            (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(3, 3))\n",
    "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (2): Conv2d(32, 5, kernel_size=(9, 9), stride=(1, 1))\n",
    "            (3): Flatten(start_dim=1, end_dim=-1)\n",
    "            (4): Linear(in_features=2880, out_features=2048, bias=True)\n",
    "            (5): ReLU()\n",
    "            (6): Linear(in_features=2048, out_features=512, bias=True)\n",
    "            (7): ReLU()\n",
    "            (8): Linear(in_features=512, out_features=3, bias=True)\n",
    "            (9): ReLU()\n",
    "          )\n",
    "        )\n",
    "        \"\"\"\n",
    "        # epoch stats\n",
    "        writer.add_scalar(\"Loss/train\", epoch_loss, epoch)\n",
    "        writer.add_histogram(\"conv1.bias\",   net.net[0].bias, epoch)\n",
    "        writer.add_histogram(\"conv1.weight\", net.net[0].weight, epoch)\n",
    "        writer.add_histogram(\"conv2.bias\",   net.net[0].bias, epoch)\n",
    "        writer.add_histogram(\"conv2.weight\", net.net[0].weight, epoch)\n",
    "               \n",
    "    # See how the network did.\n",
    "    check_network_splatter(net, writer=writer)\n",
    "    writer.close()\n",
    "    #return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc526cd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network with LR=0.001 BATCH=25, SHUFFLE=True, EPOCHS=20\n",
      "run_id: 0, Epoch: 0, DeltaTime = 15.86, LastLoss = 58633.88\n",
      "run_id: 0, Epoch: 1, DeltaTime = 13.56, LastLoss = 14522.18\n",
      "run_id: 0, Epoch: 2, DeltaTime = 13.49, LastLoss = 7603.36\n",
      "run_id: 0, Epoch: 3, DeltaTime = 13.48, LastLoss = 4701.42\n",
      "run_id: 0, Epoch: 4, DeltaTime = 13.76, LastLoss = 3599.63\n",
      "run_id: 0, Epoch: 5, DeltaTime = 13.99, LastLoss = 2743.38\n",
      "run_id: 0, Epoch: 6, DeltaTime = 13.82, LastLoss = 2274.44\n",
      "run_id: 0, Epoch: 7, DeltaTime = 13.58, LastLoss = 1946.04\n",
      "run_id: 0, Epoch: 8, DeltaTime = 13.78, LastLoss = 1567.32\n",
      "run_id: 0, Epoch: 9, DeltaTime = 13.88, LastLoss = 1441.15\n",
      "run_id: 0, Epoch: 10, DeltaTime = 13.61, LastLoss = 1369.19\n",
      "run_id: 0, Epoch: 11, DeltaTime = 13.54, LastLoss = 1254.95\n",
      "run_id: 0, Epoch: 12, DeltaTime = 13.50, LastLoss = 1140.06\n",
      "run_id: 0, Epoch: 13, DeltaTime = 13.90, LastLoss = 1071.94\n",
      "run_id: 0, Epoch: 14, DeltaTime = 13.85, LastLoss = 1034.19\n",
      "run_id: 0, Epoch: 15, DeltaTime = 13.51, LastLoss = 994.85\n",
      "run_id: 0, Epoch: 16, DeltaTime = 12.99, LastLoss = 932.41\n",
      "run_id: 0, Epoch: 17, DeltaTime = 12.98, LastLoss = 905.09\n",
      "run_id: 0, Epoch: 18, DeltaTime = 12.85, LastLoss = 909.64\n",
      "run_id: 0, Epoch: 19, DeltaTime = 12.86, LastLoss = 839.54\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'check_network_splatter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18588/587346684.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mparam_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training network with LR={} BATCH={}, SHUFFLE={}, EPOCHS={}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18588/508227500.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(learning_rate, batch_size, shuffle, epochs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;31m# See how the network did.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m     \u001b[0mcheck_network_splatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;31m#return net\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'check_network_splatter' is not defined"
     ]
    }
   ],
   "source": [
    "for run_id, (lr, batch_size, shuffle, epochs) in enumerate(product(*param_values)):\n",
    "    print(\"Training network with LR={} BATCH={}, SHUFFLE={}, EPOCHS={}\".format(lr, batch_size, str(shuffle), epochs))\n",
    "    train(lr, batch_size, shuffle, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecd85630",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mem_used' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18588/2239710817.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmem_used\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mem_used' is not defined"
     ]
    }
   ],
   "source": [
    "mem_used()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723e8133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d824ce7",
   "metadata": {},
   "source": [
    "Run this command from the dirctory containing \"logdir\" to stand up tensorboard log viewer\n",
    "```sh\n",
    "tensorboard --logdir=runs\n",
    "```\n",
    "Then go to http://localhost:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d565ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e660af3098993ea5160fd9270f74e6db286e749e474b6bbf115c5a1892218496"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
